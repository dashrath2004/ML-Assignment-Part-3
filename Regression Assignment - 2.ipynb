{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa0fe1f-530e-4e3a-bfa8-63021d275ff4",
   "metadata": {},
   "source": [
    "# 27th March Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb66bd-661b-4892-83d4-c920028e9446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53b31d9d-7e57-4667-9a2b-7180da00496b",
   "metadata": {},
   "source": [
    "## Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3a10c-2c8d-47b5-8f68-26959977c82a",
   "metadata": {},
   "source": [
    "- > R-squared is used to get accuracy of the model.\n",
    "\n",
    "- > We can find the R-Squared with the help of r2_square function,which is from sklearn library.\n",
    "\n",
    "* Formula \n",
    "\n",
    "1 - SS Res / SS Total\n",
    " \n",
    "where,\n",
    "\n",
    "SS Res - Sum of Squared Residual - ∑ (Yi - Ŷ) ** 2\n",
    "    \n",
    "SS Total - Sum of Squared Total - ∑ (Yi - ȳ) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dc52f-56a8-4792-9fee-6697e8537dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7321e324-8d7a-4e71-9908-711cdf270b90",
   "metadata": {},
   "source": [
    "# Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becdb123-25ad-4085-9ef9-a736ad9e1cbd",
   "metadata": {},
   "source": [
    "- > Adjusted R-Squared is used to find the accuracy as R-Square.\n",
    "\n",
    "- > But there is a little drawback in R-Squared.When we add extra feature for train the model, the accuracy will increase even if that feature is not relatade to model.\n",
    "\n",
    "- > To solve the problem of R-squared we use Adusted R-square.\n",
    "\n",
    "- > Adusted R-square will decrease the accuracy when we add more features.\n",
    "\n",
    "* Formula = 1 - ((1 - R-Squared) * (N - 1)) / (N - P - 1)\n",
    "\n",
    "where,\n",
    "\n",
    "N = Number of Datapoints\n",
    "\n",
    "P = Number of unique features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834c21e-4e65-489f-aecf-37c8c66070eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f97c7f-55db-4adc-a377-6e8142da282e",
   "metadata": {},
   "source": [
    "## Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ea2b2-124d-4af8-ad9c-a5d52583a174",
   "metadata": {},
   "source": [
    "- > Adjusted R-squared is a valuable metric in multiple regression scenarios, especially when dealing with model comparison, feature selection, avoiding overfitting, and assessing model quality. However, it is essential to consider other factors and metrics in conjunction with adjusted R-squared to make well-informed decisions about your regression models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01abf0-7571-4bd9-9f4a-e550a974047a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6348993-b4f3-4747-b318-45a3945cae00",
   "metadata": {},
   "source": [
    "## Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e67ee-8c16-4f8a-822d-32c8f33afebb",
   "metadata": {},
   "source": [
    "- > RMSE, MSE, and MAE are cost functions.\n",
    "\n",
    "- > This cost functions play important role to find the best fit line.\n",
    "\n",
    "- > Cost funtions help us to find best theta values.\n",
    "\n",
    "## Formulas :\n",
    "\n",
    "MSE - ∑ (Yi - Ŷ) ** 2 / n\n",
    "\n",
    "MAE - ∑ |Yi - Ŷ| ** 2 / n\n",
    "\n",
    "RMSE - √ ∑ (Yi - Ŷ) ** 2 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5fdc4-137a-46a7-8ab1-7a9cbfd86425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9595e9-c170-4cd3-a21c-036ff04f3bd3",
   "metadata": {},
   "source": [
    "## Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff04c3-398a-4cee-a029-83d1bc5bcca5",
   "metadata": {},
   "source": [
    "## MSE\n",
    "\n",
    "* Advantages\n",
    "\n",
    "- > It has only global minima.\n",
    "\n",
    "- > It is differenciable.\n",
    "\n",
    "* Disadvantages\n",
    "\n",
    "- > It is not in a same unit.\n",
    "\n",
    "- > Not robust outlier.\n",
    "\n",
    "## MAE\n",
    "\n",
    "* Advantages\n",
    "\n",
    "- > Robust to outlier.\n",
    "\n",
    "- > Its in a same unit.\n",
    "\n",
    "* Disadvantages\n",
    "\n",
    "- > It take more time for convergence.\n",
    "\n",
    "## RMSE\n",
    "\n",
    "* Advantages\n",
    "\n",
    "- > It is in a same unit.\n",
    "\n",
    "- > It is differenciable.\n",
    "\n",
    "* Disadvantages\n",
    "\n",
    "- > Not robust to outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debaccf-c4c2-4939-93e1-ef2d2732c4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd91bf06-9447-4495-a294-1d7aa27d69ad",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649c124-dc2a-49c4-9b31-0606aa0ef859",
   "metadata": {},
   "source": [
    "- > Lasso regularization is also known as L1 Regularization.\n",
    "\n",
    "- > Lasso and Ridge both are work for different purposes.\n",
    "\n",
    "- > Lasso regression is used for feature selection and Ridge regression is used for reduce the overfitting.\n",
    "\n",
    "- > Cost functions of both are different.\n",
    "\n",
    "1. Lasso Regression\n",
    "\n",
    "- > Cost Function : ∑(Yi - Ŷi) ** 2 / n + λ * ∑ (Slope) ** 2\n",
    "\n",
    "2. Ridge Regression\n",
    "\n",
    "- > Cost Function : ∑(Yi - Ŷi) ** 2 / n + λ * ∑ |Slope| ** 2\n",
    "\n",
    "* Lasso regularization is more appropriate when we have to remove an unrelated feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a33ba5-0759-4f7f-95b9-b14479337e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c61b1b2-3cef-4579-8c28-a7d1e11cad1d",
   "metadata": {},
   "source": [
    "## Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7c3e5-44ed-4153-a076-9d0941cefe76",
   "metadata": {},
   "source": [
    "- > Ridge regression is used to prevent overfitting in machine learning.\n",
    "\n",
    "- > Simple regression model perform well in training model but sometimes they doesn't perform well in testing model.\n",
    "\n",
    "- > Cost function of ridge regression performs main role.\n",
    "\n",
    "- > Cost function of ridge regression will never become 0 , it always have some positive value.\n",
    "\n",
    "- > That positive value remains because of the relation of 'Lambda' and 'Theta'.\n",
    "\n",
    "- > With the help of this techniques model will perform bad in taining dataset but its performance will increase for test dataset.\n",
    "\n",
    "* Example\n",
    "\n",
    "- > Let suppose we are creating Multiple linear regression model with some features name route,airline,duration,etc,.\n",
    "\n",
    "- > Now we can apply L2 regulatization on it.\n",
    "\n",
    "- > It will decrease the coefficient values, but zero.\n",
    "\n",
    "- > In this technique model will always give some error but that is good for testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385cff8-32e7-4c3d-8f49-0292f1a6b745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb640899-0c4a-4ddb-8846-689120e8d626",
   "metadata": {},
   "source": [
    "## Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef1d2d-1c8f-472c-ab16-5d0382760aaf",
   "metadata": {},
   "source": [
    "* This are the limitations and because of this limitations they may not always be the best choise :\n",
    "    \n",
    "- > When we use Lasso ragularization we can lose some important information,and becuase of it we can't take precise decision.\n",
    "\n",
    "- > Regularized models are not usefull when variables doesn't have linear relationship.\n",
    "\n",
    "- > It becomes very complex sometimes when number of features are more.\n",
    "\n",
    "- > It has very expensive computational cost,on the other hand simple linear models give same results at low computational cost.\n",
    "\n",
    "- > Regularized models are depands on hyperparameter,if that parameter is too high so we lose some important feature and if that parameter is too small so we can't elemenate deserved feature also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847e722-a7f6-4d77-a5d1-dfa4ff29fbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8895f598-6bf0-4bcd-b8ea-52a5fb24ce70",
   "metadata": {},
   "source": [
    "## Q9. You are comparing the performance of two regression models using different evaluation metrics.Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better performer, and why? Are there any limitations to your choice of metric?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fcb15-c817-4548-9fe4-ee4f18d6b021",
   "metadata": {},
   "source": [
    "- > We can choose any model according to context and priorities.\n",
    "\n",
    "- > If there is some outliers in model so we should choose Model B with MAE of 8.\n",
    "\n",
    "- > As compare to error rate Model B is good.\n",
    "\n",
    "- > If we specifically emphsize with large error or our modeling goal align with RMSE so we can choose Model A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9192213-55b8-422c-ab9e-15fd3a13b813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df212bbb-653e-4181-b59b-cfb5c29fce9a",
   "metadata": {},
   "source": [
    "## Q10. You are comparing the performance of two regularized linear models using different types of regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the better performer, and why? Are there any trade-offs or limitations to your choice of regularization method?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa799992-936b-4447-bf77-bd6f36c7e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "- > We can choose best model with the help of our priorities.\n",
    "\n",
    "- > Ridge regression is used for reduce overfitting and Lasso regression is used for feature selection.\n",
    "\n",
    "- > Ridge regression decrease the value of coefficient and Lasso regression drive some coefficient to zero.\n",
    "\n",
    "- > If our priority is to reduce overfitting so we can choose Ridge regression.\n",
    "\n",
    "- > If our priority is to elemenate some unrelated feature so we can choose Lasso regression.\n",
    "\n",
    "- > If every data is important for model so we can go with Ridge regression.\n",
    "\n",
    "- > If our predictors are highly correlated(multicolinearity) so we can ignore the lasso regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
